# Overview
In order to align our chat agent, we need to have some strategy to have it learn the inputs and appropriate responses. There are generally two phases - offline learning and online learning. In this case, offline learning involves supervised training data. Online learning will involve adapting to continual feedback - the way this has traditionally been done as of late is through reinforcement learning. This document will outline how the initial training data was curated and generated, along with the associated challenges.

# Training Data Generation
## Input Generation
Our goal is to to have the agent be able to recognize common inputs that could be entered into our chat model. While this could theoretically be anything, we can make some simple assumptions about the subject matter that people will be discussing, as well as their emotions behind it. More concretely, we want to create inputs that encompass a diversity of designations for a variety of topics:

- Themes in Self-doubt: Perfectionism, fear of failure, self-doubt
- Situational categories: Giving Presentations, Relationship Struggles
- Emotions: Angry, Sad, Confused

To curate this dataset, I focused on two sources of curation: synthetic data generation and real data collection. There are pros and cons to each approach:
**Synthetic Data Generation**
- Pro: You have control over the inputs that are generated.
- Pro: You can create as many as you want
- Con: Lack of diversity, 
- Con: Inputs generated by LLMs may not be conducive to learning new information

**Real Data Collection**
- Pro: It's real data, and so it contains the nuances of real human input.
- Pro: Finding diversity in inputs is easier, because there's already natural diversity in how people speak
- Con: You don't have direct control over the inputs, and so you're prone to outliers and datapoints that may not be representative of the underlying patterns.
- Con: Need to do the work to sample the "right" datapoints from the larger population

