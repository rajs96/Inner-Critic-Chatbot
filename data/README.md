# Overview
In order to align our chat agent, we need to have some strategy to have it learn the inputs and appropriate responses. There are generally two phases - offline learning and online learning. In this case, offline learning involves supervised training data. Online learning will involve adapting to continual feedback - the way this has traditionally been done as of late is through reinforcement learning. This document will outline how the initial training data was curated and generated, along with the associated challenges.

# Training Data Generation
## Input Generation
Our goal is to to have the agent be able to recognize common inputs that could be entered into our chat model. While this could theoretically be anything, we can make some simple assumptions about the subject matter that people will be discussing, as well as their emotions behind it. More concretely, we want to create inputs that encompass a diversity of designations for a variety of topics:

- Themes in Self-doubt: Perfectionism, fear of failure, self-doubt
- Situational categories: Giving Presentations, Relationship Struggles
- Emotions: Angry, Sad, Confused

To curate this dataset, I focused on two sources of curation: synthetic data generation and real data collection. There are pros and cons to each approach:

**Synthetic Data Generation**
- Pro: You have control over the inputs that are generated.
- Pro: You can create as many as you want
- Con: Lack of diversity and may not capture real human language patterns
- Con: Inputs generated by LLMs may not be conducive to learning new information

**Real Data Collection**
- Pro: It's real data, and so it contains the nuances of real human input.
- Pro: Finding diversity in inputs is easier, because there's already natural diversity in how people speak
- Con: You don't have direct control over the inputs, and so you're prone to outliers and other datapoints that may not be representative of the underlying patterns.
- Con: Need to do the work to sample the "right" datapoints from the larger population

In order to get the best of both worlds, I took a hybrid approach.

### Synthetic Data Generation Approach

This synthetic data generation approach has two parts: scenario generation and what I call "seed instance" generation.

The *scenario generation* step involves using an LLM to generate a variety of hypothetical scenarios that simulate real-life scenarios that someone may describe when talking about self-doubt issues. The LLM is provided a [system prompt](../prompts/system_messages/scenario_generation_system_message.txt) and an [input prompt template](../prompts/input_messages/scenario_generation_input_message.txt). The input prompt takes in a scenario type and generates 10 scenarios based on that scenario type. 

For example, for the scenario type "Giving Presentations", the LLM generated some scenarios:
- A college student is terrified of giving a presentation in front of her class due to public speaking anxiety.
- A businessman is having trouble convincing his team about his new plan due to a lack of effective presentation skills.
- A researcher is struggling to present his complex findings in a simplified, understandable manner to a general audience.

